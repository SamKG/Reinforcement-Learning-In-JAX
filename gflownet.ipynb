{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "import functools\n",
    "import itertools\n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import distrax\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"num_bits\"])\n",
    "def num_to_binarray(num, num_bits):\n",
    "    return jnp.array(jax.vmap(lambda i: num >> i & 1)(jnp.arange(num_bits)), dtype=jnp.int32)\n",
    "\n",
    "class GridEnv(eqx.Module):\n",
    "    state: jnp.ndarray\n",
    "    r0: float = eqx.static_field()\n",
    "    r1: float = eqx.static_field()\n",
    "    r2: float = eqx.static_field()\n",
    "    horizon: int = eqx.static_field()\n",
    "    ndim: int = eqx.static_field()\n",
    "    action_space: distrax.Categorical = eqx.static_field()\n",
    "\n",
    "    def __init__(self, horizon, r0, r1, r2, ndim=2):\n",
    "        self.state: jnp.ndarray = jnp.zeros(ndim, dtype=jnp.int32)\n",
    "        self.ndim = ndim\n",
    "        self.r0 = r0\n",
    "        self.r1 = r1\n",
    "        self.r2 = r2\n",
    "        self.horizon = horizon\n",
    "        self.action_space = distrax.Categorical(probs=jnp.ones(ndim + 1))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def state_to_onehot(self, state):\n",
    "        '''\n",
    "        Converts a environment state to a one-hot encoded observation, for use with neural networks.\n",
    "        '''\n",
    "        observation = jnp.zeros((self.ndim*self.horizon,), dtype=jnp.float32)\n",
    "        observation = observation.at[jnp.arange(self.ndim) * self.horizon + state].set(1)\n",
    "        return observation\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def reward(self, state) -> jnp.ndarray:\n",
    "        # normalize state\n",
    "        tmp = jnp.abs(state/(self.horizon - 1) - 0.5) \n",
    "        indicator_r1 = jnp.prod(tmp > 0.25)\n",
    "        indicator_r2 = jnp.prod((tmp > 0.3) *  (tmp < 0.4))\n",
    "        r = self.r0 + self.r1 * indicator_r1 + self.r2 * indicator_r2\n",
    "        return r\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def get_all_state_rewards(self):\n",
    "        states = jnp.array(list(itertools.product(list(range(self.horizon)), repeat=self.ndim)))\n",
    "        valids = jax.vmap(self.state_valid)(states)\n",
    "        return {\n",
    "            \"states\": states,\n",
    "            \"valids\": valids,\n",
    "            \"rewards\": jax.vmap(self.reward)(states) * valids\n",
    "        }\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def state_valid(self, state):\n",
    "        '''\n",
    "        Checks if a state is in the observation space.\n",
    "        '''\n",
    "        return jnp.all(state >= 0) * jnp.all(state < self.horizon) *  (jnp.sum(state >= self.horizon - 1) <= 1)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def step(grid, action):\n",
    "        grid = jax.lax.cond(action < grid.state.shape[0], \n",
    "            lambda _: eqx.tree_at(\n",
    "                lambda grid: grid.state, grid, grid.state.at[action].add(1)\n",
    "            ), lambda _: grid, None)\n",
    "        reward = grid.reward(grid.state)\n",
    "        stop_step = action == grid.state.shape[0]\n",
    "        horizon_finished = jnp.max(grid.state) >= grid.horizon - 1\n",
    "\n",
    "\n",
    "        done = jax.lax.cond(horizon_finished, lambda _: True,  lambda _: stop_step, None)\n",
    "        return (\n",
    "            grid,\n",
    "            reward,\n",
    "            done \n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def reset(self):\n",
    "        grid = eqx.tree_at(\n",
    "            lambda grid: grid.state, self, jnp.zeros_like(self.state)\n",
    "        )\n",
    "        return grid \n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def inverse_transitions(self, state):\n",
    "        '''\n",
    "        Returns a list of all possible state + /actions that can transition to the given state. \n",
    "        Each element of the resulting PyTree also has a valid boolean, indicating if the state/action is valid.\n",
    "        '''\n",
    "        def get_index_parent(idx: int):\n",
    "            tmp = state.at[idx].add(-1)\n",
    "            pred = self.state_valid(tmp)\n",
    "            return {\"states\":tmp, \"valid\":pred, \"actions\":idx}\n",
    "        return jax.vmap(get_index_parent)(jnp.arange(state.shape[0])) \n",
    "\n",
    "    \n",
    "    @eqx.filter_jit\n",
    "    def transitions(self, state):\n",
    "        def get_index_child(idx: int):\n",
    "            tmp = state.at[idx].add(1)\n",
    "            pred = self.state_valid(tmp)\n",
    "            return {\"states\":tmp, \"valid\":pred, \"actions\":idx}\n",
    "        return jax.vmap(get_index_child)(jnp.arange(state.shape[0])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gflownet import FlowNetwork\n",
    "\n",
    "env = GridEnv(8, 0.1, 0.5, 2.0, 4)\n",
    "all_state_rewards = env.get_all_state_rewards()\n",
    "key = jax.random.PRNGKey(0)\n",
    "agent = FlowNetwork(env.state_to_onehot(env.state).shape[0], [64], key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 14 49 54]\n",
      "[[1 1]\n",
      " [1 6]\n",
      " [6 1]\n",
      " [6 6]]\n",
      "Counter({0.10000000149011612: 48, 0.6000000238418579: 11, 2.5999999046325684: 4})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "rewards = all_state_rewards[\"rewards\"][all_state_rewards[\"valids\"] == 1]\n",
    "valid_states = all_state_rewards[\"states\"][all_state_rewards[\"valids\"] == 1]\n",
    "\n",
    "best_reward = jnp.max(rewards)\n",
    "reward_modes = jnp.argwhere(rewards == best_reward).flatten()\n",
    "print(reward_modes)\n",
    "print(valid_states[reward_modes])\n",
    "\n",
    "import seaborn as sns\n",
    "sns.histplot(rewards)\n",
    "\n",
    "print(Counter([r.item() for r in rewards]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def policy_trajectory(\n",
    "    agent: FlowNetwork,\n",
    "    env: GridEnv,\n",
    "    steps_per_episode: int,\n",
    "    key: jax.random.KeyArray,\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Collects steps_per_episode steps from the environment using the agent's policy. Note that there may be multiple terminal states in the trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    def loop(loopstate, _):\n",
    "        key = jax.random.split(loopstate[0], 2)[1]\n",
    "        env = loopstate[1]\n",
    "\n",
    "        state = env.state\n",
    "        encoded_state = env.state_to_onehot(state)\n",
    "        transitions = env.transitions(env.state)\n",
    "        flows = jnp.hstack(\n",
    "            jax.vmap(functools.partial(agent, encoded_state))(transitions[\"actions\"])\n",
    "        )\n",
    "        flows = flows * transitions[\"valid\"]\n",
    "        action = distrax.Categorical(logits=flows).sample(seed=key)\n",
    "        env, reward, done = env.step(action)\n",
    "        env = jax.lax.cond(done, lambda _: env.reset(), lambda _: env, None)\n",
    "        reward = jax.lax.cond(done, lambda _: reward, lambda _: 0.0, None)\n",
    "\n",
    "        return (\n",
    "            (key, env),\n",
    "            {\n",
    "                \"states\": state,\n",
    "                \"actions\": action,\n",
    "                \"rewards\": reward,\n",
    "                \"dones\": done,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    (key, env), trajectory = jax.lax.scan(loop, (key, env), jnp.arange(steps_per_episode))\n",
    "\n",
    "    # mask out the last episode if it is not done\n",
    "    def mask_dones(is_done, curr_done):\n",
    "        is_done = jax.lax.cond(curr_done, lambda _: True, lambda _: is_done, None)\n",
    "        return (is_done, jax.lax.cond(is_done, lambda _: 1.0, lambda _: 0.0, None))\n",
    "\n",
    "    dones_mask = jax.lax.scan(mask_dones, False, trajectory[\"dones\"], reverse=True)[1]\n",
    "\n",
    "    return {\n",
    "        \"episode_mask\": dones_mask,\n",
    "        **trajectory\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optax\n",
    "optimizer = optax.adam(1e-3)\n",
    "optimizer_state = optimizer.init(eqx.filter(agent, eqx.filters.is_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 76.37726593017578:   1%|          | 10/1000 [00:04<07:53,  2.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/samyakg/tigress/Reinforcement-Learning-In-JAX/gflownet.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdella-gpu/home/samyakg/tigress/Reinforcement-Learning-In-JAX/gflownet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m keys \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39msplit(key, \u001b[39m10000\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdella-gpu/home/samyakg/tigress/Reinforcement-Learning-In-JAX/gflownet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m (t\u001b[39m:=\u001b[39m trange(\u001b[39m1000\u001b[39m)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdella-gpu/home/samyakg/tigress/Reinforcement-Learning-In-JAX/gflownet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     loss, agent, env, optimizer_state \u001b[39m=\u001b[39m train_flownet(agent, keys[i], env, optimizer_state)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdella-gpu/home/samyakg/tigress/Reinforcement-Learning-In-JAX/gflownet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     t\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdella-gpu/home/samyakg/tigress/Reinforcement-Learning-In-JAX/gflownet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.conda/envs/rl-in-jax/lib/python3.9/site-packages/equinox/jit.py:95\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(_JitWrapper__self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(__self, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mreturn\u001b[39;00m __self\u001b[39m.\u001b[39;49m_fun_wrapper(\u001b[39mFalse\u001b[39;49;00m, args, kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/rl-in-jax/lib/python3.9/site-packages/equinox/jit.py:91\u001b[0m, in \u001b[0;36m_JitWrapper._fun_wrapper\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached\u001b[39m.\u001b[39mlower(dynamic, static)\n\u001b[1;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     dynamic_out, static_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached(dynamic, static)\n\u001b[1;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m combine(dynamic_out, static_out\u001b[39m.\u001b[39mvalue)\n",
      "File \u001b[0;32m~/.conda/envs/rl-in-jax/lib/python3.9/site-packages/equinox/module.py:263\u001b[0m, in \u001b[0;36mModule.tree_unflatten\u001b[0;34m(cls, aux, dynamic_field_values)\u001b[0m\n\u001b[1;32m    256\u001b[0m             dynamic_field_values\u001b[39m.\u001b[39mappend(value)\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(dynamic_field_values), (\n\u001b[1;32m    258\u001b[0m         \u001b[39mtuple\u001b[39m(dynamic_field_names),\n\u001b[1;32m    259\u001b[0m         \u001b[39mtuple\u001b[39m(static_field_names),\n\u001b[1;32m    260\u001b[0m         \u001b[39mtuple\u001b[39m(static_field_values),\n\u001b[1;32m    261\u001b[0m     )\n\u001b[0;32m--> 263\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtree_unflatten\u001b[39m(\u001b[39mcls\u001b[39m, aux, dynamic_field_values):\n\u001b[1;32m    265\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    266\u001b[0m     dynamic_field_names, static_field_names, static_field_values \u001b[39m=\u001b[39m aux\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.gflownet import flow_matching_loss\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def train_flownet(agent, key, env, optimizer_state):\n",
    "    trajectories = jax.vmap(functools.partial(policy_trajectory, agent, env, 1000))(jax.random.split(key, 16))\n",
    "    def loss_grad(trajectory):\n",
    "        loss, gradients = eqx.filter_value_and_grad(flow_matching_loss)(agent, trajectory[\"states\"], trajectory[\"rewards\"], trajectory[\"episode_mask\"], env.transitions, env.inverse_transitions, env.state_to_onehot)\n",
    "        return {\"loss\":loss, \"gradients\":gradients}\n",
    "    loss_grads = jax.vmap(loss_grad)(trajectories)\n",
    "    gradients_avg = jax.tree_util.tree_map(lambda x: jnp.mean(x, axis=0), loss_grads[\"gradients\"])\n",
    "    updates, optimizer_state = optimizer.update(gradients_avg, optimizer_state, agent)\n",
    "    agent = eqx.apply_updates(agent, updates)\n",
    "    return loss_grads[\"loss\"].mean(), agent, env, optimizer_state\n",
    "\n",
    "losses = []\n",
    "keys = jax.random.split(key, 10000)\n",
    "for i in (t:= trange(1000)):\n",
    "    loss, agent, env, optimizer_state = train_flownet(agent, keys[i], env, optimizer_state)\n",
    "    t.set_description(f\"Loss: {loss}\")\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys = jax.random.split(key, 100)\n",
    "rewards = []\n",
    "trajectories = jax.vmap(functools.partial(policy_trajectory, agent, env, 1000))(keys)\n",
    "rewards = jnp.max(trajectories[\"rewards\"], axis=-1)\n",
    "rewards_bestidx = jnp.argmax(trajectories[\"rewards\"], axis=-1)\n",
    "final_reward_action = jnp.take_along_axis(trajectories[\"actions\"], rewards_bestidx[..., None], axis=-1)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.histplot(rewards)\n",
    "print(set([k.item() for k in trajectories[\"actions\"].flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00438e6e6465405d7e64b7e989cc9eee8ebcecea092b0d83b9c6ec6038b09b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
