{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "import functools\n",
    "import itertools\n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import distrax\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"num_bits\"])\n",
    "def num_to_binarray(num, num_bits):\n",
    "    return jnp.array(jax.vmap(lambda i: num >> i & 1)(jnp.arange(num_bits)), dtype=jnp.int32)\n",
    "\n",
    "class GridEnv(eqx.Module):\n",
    "    state: jnp.ndarray\n",
    "    r0: float = eqx.static_field()\n",
    "    r1: float = eqx.static_field()\n",
    "    r2: float = eqx.static_field()\n",
    "    horizon: int = eqx.static_field()\n",
    "    ndim: int = eqx.static_field()\n",
    "    action_space: distrax.Categorical = eqx.static_field()\n",
    "\n",
    "    def __init__(self, horizon, r0, r1, r2, ndim=2):\n",
    "        self.state: jnp.ndarray = jnp.zeros(ndim, dtype=jnp.int32)\n",
    "        self.ndim = ndim\n",
    "        self.r0 = r0\n",
    "        self.r1 = r1\n",
    "        self.r2 = r2\n",
    "        self.horizon = horizon\n",
    "        self.action_space = distrax.Categorical(probs=jnp.ones(ndim + 1))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def state_to_onehot(self, state):\n",
    "        '''\n",
    "        Converts a environment state to a one-hot encoded observation, for use with neural networks.\n",
    "        '''\n",
    "        observation = jnp.zeros((self.ndim*self.horizon,), dtype=jnp.float32)\n",
    "        observation = observation.at[jnp.arange(self.ndim) * self.horizon + state].set(1)\n",
    "        return observation\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def reward(self, state) -> jnp.ndarray:\n",
    "        # normalize state\n",
    "        tmp = jnp.abs(state/(self.horizon - 1) - 0.5) \n",
    "        indicator_r1 = jnp.prod(tmp > 0.25)\n",
    "        indicator_r2 = jnp.prod((tmp > 0.3) *  (tmp < 0.4))\n",
    "        r = self.r0 + self.r1 * indicator_r1 + self.r2 * indicator_r2\n",
    "        return r\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def get_all_state_rewards(self):\n",
    "        states = jnp.array(list(itertools.product(list(range(self.horizon)), repeat=self.ndim)))\n",
    "        valids = jax.vmap(self.state_valid)(states)\n",
    "        return {\n",
    "            \"states\": states,\n",
    "            \"valids\": valids,\n",
    "            \"rewards\": jax.vmap(self.reward)(states) * valids\n",
    "        }\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def state_valid(self, state):\n",
    "        '''\n",
    "        Checks if a state is in the observation space.\n",
    "        '''\n",
    "        return jnp.all(state >= 0) * jnp.all(state < self.horizon) *  (jnp.sum(state >= self.horizon - 1) <= 1)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def step(grid, action):\n",
    "        grid = jax.lax.cond(action < grid.state.shape[0], \n",
    "            lambda _: eqx.tree_at(\n",
    "                lambda grid: grid.state, grid, grid.state.at[action].add(1)\n",
    "            ), lambda _: grid, None)\n",
    "        reward = grid.reward(grid.state)\n",
    "        stop_step = action == grid.state.shape[0]\n",
    "        horizon_finished = jnp.max(grid.state) >= grid.horizon - 1\n",
    "\n",
    "\n",
    "        done = jax.lax.cond(horizon_finished, lambda _: True,  lambda _: stop_step, None)\n",
    "        return (\n",
    "            grid,\n",
    "            reward,\n",
    "            done \n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def reset(self):\n",
    "        grid = eqx.tree_at(\n",
    "            lambda grid: grid.state, self, jnp.zeros_like(self.state)\n",
    "        )\n",
    "        return grid \n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def inverse_transitions(self, state):\n",
    "        '''\n",
    "        Returns a list of all possible state + /actions that can transition to the given state. \n",
    "        Each element of the resulting PyTree also has a valid boolean, indicating if the state/action is valid.\n",
    "        '''\n",
    "        def get_index_parent(idx: int):\n",
    "            tmp = state.at[idx].add(-1)\n",
    "            pred = self.state_valid(tmp)\n",
    "            return {\"states\":tmp, \"valid\":pred, \"actions\":idx}\n",
    "        return jax.vmap(get_index_parent)(jnp.arange(state.shape[0])) \n",
    "\n",
    "    \n",
    "    @eqx.filter_jit\n",
    "    def transitions(self, state):\n",
    "        def get_index_child(idx: int):\n",
    "            tmp = state.at[idx].add(1)\n",
    "            pred = self.state_valid(tmp)\n",
    "            return {\"states\":tmp, \"valid\":pred, \"actions\":idx}\n",
    "        return jax.vmap(get_index_child)(jnp.arange(state.shape[0])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gflownet import FlowNetwork\n",
    "\n",
    "env = GridEnv(8, 0.1, 0.5, 2.0, 4)\n",
    "all_state_rewards = env.get_all_state_rewards()\n",
    "key = jax.random.PRNGKey(0)\n",
    "agent = FlowNetwork(\n",
    "    env.state_to_onehot(env.state).shape[0],\n",
    "    [256, 256],\n",
    "    env.action_space.logits.shape[0],\n",
    "    key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 562  567  602  607  877  882  917  922 3012 3017 3052 3057 3327 3332\n",
      " 3367 3372]\n",
      "[[1 1 1 1]\n",
      " [1 1 1 6]\n",
      " [1 1 6 1]\n",
      " [1 1 6 6]\n",
      " [1 6 1 1]\n",
      " [1 6 1 6]\n",
      " [1 6 6 1]\n",
      " [1 6 6 6]\n",
      " [6 1 1 1]\n",
      " [6 1 1 6]\n",
      " [6 1 6 1]\n",
      " [6 1 6 6]\n",
      " [6 6 1 1]\n",
      " [6 6 1 6]\n",
      " [6 6 6 1]\n",
      " [6 6 6 6]]\n",
      "Counter({0.10000000149011612: 3584, 0.6000000238418579: 173, 2.5999999046325684: 16})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "rewards = all_state_rewards[\"rewards\"][all_state_rewards[\"valids\"] == 1]\n",
    "valid_states = all_state_rewards[\"states\"][all_state_rewards[\"valids\"] == 1]\n",
    "\n",
    "best_reward = jnp.max(rewards)\n",
    "reward_modes = jnp.argwhere(rewards == best_reward).flatten()\n",
    "print(reward_modes)\n",
    "print(valid_states[reward_modes])\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(rewards)\n",
    "\n",
    "rc = (Counter([r.item() for r in rewards]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def policy_trajectory(\n",
    "    agent: FlowNetwork,\n",
    "    env: GridEnv,\n",
    "    steps_per_episode: int,\n",
    "    key: jax.random.KeyArray,\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Collects steps_per_episode steps from the environment using the agent's policy. Note that there may be multiple terminal states in the trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    def loop(loopstate, _):\n",
    "        key = jax.random.split(loopstate[0], 2)[1]\n",
    "        env = loopstate[1]\n",
    "\n",
    "        state = env.state\n",
    "        encoded_state = env.state_to_onehot(state)\n",
    "        transitions = env.transitions(env.state)\n",
    "        flows = agent(encoded_state)\n",
    "        flows = flows * jnp.concatenate([transitions[\"valid\"], jnp.array([True])])\n",
    "        action = distrax.Categorical(logits=flows).sample(seed=key)\n",
    "        env, reward, done = env.step(action)\n",
    "        env = jax.lax.cond(done, lambda _: env.reset(), lambda _: env, None)\n",
    "        reward = jax.lax.cond(done, lambda _: reward, lambda _: 0.0, None)\n",
    "\n",
    "        return (\n",
    "            (key, env),\n",
    "            {\n",
    "                \"states\": state,\n",
    "                \"actions\": action,\n",
    "                \"rewards\": reward,\n",
    "                \"dones\": done,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    (key, env), trajectory = jax.lax.scan(\n",
    "        loop, (key, env), jnp.arange(steps_per_episode)\n",
    "    )\n",
    "\n",
    "    # mask out the last episode if it is not done\n",
    "    def mask_dones(is_done, curr_done):\n",
    "        is_done = jax.lax.cond(curr_done, lambda _: True, lambda _: is_done, None)\n",
    "        return (is_done, jax.lax.cond(is_done, lambda _: 1.0, lambda _: 0.0, None))\n",
    "\n",
    "    dones_mask = jax.lax.scan(mask_dones, False, trajectory[\"dones\"], reverse=True)[1]\n",
    "\n",
    "    return trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "optimizer = optax.adam(1e-3)\n",
    "optimizer_state = optimizer.init(eqx.filter(agent, eqx.filters.is_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0879134606511798e-06: 100%|██████████| 10000/10000 [01:19<00:00, 125.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.gflownet import flow_matching_loss\n",
    "from tqdm import trange\n",
    "\n",
    "@eqx.filter_jit\n",
    "def train_flownet(agent, key, env:GridEnv, optimizer_state):\n",
    "    trajectories = jax.vmap(functools.partial(policy_trajectory, agent, env, env.ndim * env.horizon))(\n",
    "        jax.random.split(key, 16)\n",
    "    )\n",
    "\n",
    "    def loss_grad(trajectory):\n",
    "        loss, gradients = eqx.filter_value_and_grad(flow_matching_loss)(\n",
    "            agent,\n",
    "            trajectory[\"states\"],\n",
    "            trajectory[\"rewards\"],\n",
    "            trajectory[\"dones\"],\n",
    "            env.transitions,\n",
    "            env.inverse_transitions,\n",
    "            env.state_to_onehot,\n",
    "        )\n",
    "        return {\"loss\": loss, \"gradients\": gradients}\n",
    "\n",
    "    loss_grads = jax.vmap(loss_grad)(trajectories)\n",
    "    gradients_avg = jax.tree_util.tree_map(\n",
    "        lambda x: jnp.mean(x, axis=0), loss_grads[\"gradients\"]\n",
    "    )\n",
    "    updates, optimizer_state = optimizer.update(gradients_avg, optimizer_state, agent)\n",
    "    agent = eqx.apply_updates(agent, updates)\n",
    "    return loss_grads[\"loss\"].mean(), agent, env, optimizer_state\n",
    "\n",
    "\n",
    "losses = []\n",
    "keys = jax.random.split(key, 10000)\n",
    "for i in (t := trange(10000)):\n",
    "    loss, agent, env, optimizer_state = train_flownet(\n",
    "        agent, keys[i], env, optimizer_state\n",
    "    )\n",
    "    t.set_description(f\"Loss: {loss}\")\n",
    "    losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 4)\n",
      "Counter({0.6000000238418579: 9011, 0.10000000149011612: 527, 2.5999999046325684: 462})\n",
      "404\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "keys = jax.random.split(key, 10000)\n",
    "rewards = []\n",
    "trajectories = jax.vmap(functools.partial(policy_trajectory, agent, env, env.ndim*env.horizon))(keys)\n",
    "rewards = jnp.max(trajectories[\"rewards\"], axis=-1)\n",
    "rewards_bestidx = jnp.argmax(trajectories[\"rewards\"], axis=-1)\n",
    "final_reward_action = jnp.take_along_axis(\n",
    "    trajectories[\"actions\"], rewards_bestidx[..., None], axis=-1\n",
    ")\n",
    "\n",
    "print(trajectories[\"states\"].shape)\n",
    "best_states = jax.vmap(lambda s, i: s[i])(trajectories[\"states\"], rewards_bestidx)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(rewards)\n",
    "print(Counter([r.item() for r in rewards]))\n",
    "\n",
    "Counter([tuple(numpy.array(s).tolist()) for s in best_states])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00438e6e6465405d7e64b7e989cc9eee8ebcecea092b0d83b9c6ec6038b09b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
