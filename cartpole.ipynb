{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from jax import random, numpy as jnp\n",
    "import optax\n",
    "import equinox as eqx\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "import gym\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "from src.actorcritic import ActorCritic\n",
    "from src.training import policy_trajectory, step_model_ppo\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Hyperparameters:\n",
    "    batchsize=1\n",
    "    epochs=1000\n",
    "    steps_per_episode=500\n",
    "    learning_rate=0.003\n",
    "    reward_discount=0.99\n",
    "    epsilon=0.2\n",
    "\n",
    "hyperparameters = Hyperparameters()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation = env.reset()\n",
    "\n",
    "    key = random.PRNGKey(0)\n",
    "    agent = ActorCritic(observation.shape[0], env.action_space.n, [64], [64], key=key)\n",
    "\n",
    "    optimizer = optax.adam(hyperparameters.learning_rate)\n",
    "    optimizer_state = optimizer.init(eqx.filter(agent, eqx.filters.is_array))\n",
    "\n",
    "    env.seed(0)\n",
    "\n",
    "    # with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_link=True):\n",
    "    df = pd.DataFrame(columns=[\"time\", \"parameters\", \"avg_reward\"])\n",
    "    for epoch in (pbar := trange(hyperparameters.epochs)):\n",
    "        batch_rewards = []\n",
    "\n",
    "        for batchsize in range(hyperparameters.batchsize):\n",
    "            key = random.split(key, 2)[1]\n",
    "\n",
    "            import timeit\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            trajectory = policy_trajectory(\n",
    "                env,\n",
    "                agent,\n",
    "                hyperparameters.steps_per_episode,\n",
    "                hyperparameters.reward_discount,\n",
    "                key,\n",
    "            )\n",
    "\n",
    "            loss, agent, optimizer_state = step_model_ppo(\n",
    "                agent, trajectory, optimizer, optimizer_state\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                trajectory_reward = jnp.where(trajectory[\"discounts\"] == 0.0)[0][0]\n",
    "            except:\n",
    "                trajectory_reward = hyperparameters.steps_per_episode\n",
    "            batch_rewards.append(trajectory_reward)\n",
    "        avg_reward = jnp.array(batch_rewards).mean()\n",
    "        pbar.set_description(f\"{avg_reward}\")\n",
    "        save_path = Path(f\"checkpoints/cartpole/checkpoint_{epoch}.eqx\")\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df = pd.concat(\n",
    "            [\n",
    "                df,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"time\": epoch,\n",
    "                        \"parameters\": save_path.absolute().as_posix(),\n",
    "                        # \"loss\": loss,\n",
    "                        \"avg_reward\": avg_reward,\n",
    "                    },\n",
    "                    index=[0],\n",
    "                ),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        if epoch % 100 == 0:\n",
    "            eqx.tree_serialise_leaves(save_path, agent)\n",
    "            pd.to_pickle(df, save_path.parent / f\"data_{epoch}.pkl\")\n",
    "\n",
    "    # %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render an episode and save as a GIF file\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "from pyvirtualdisplay import Display\n",
    "import gym\n",
    "from src.actorcritic import ActorCritic\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "\n",
    "def render_episode(env: gym.Env, model: ActorCritic, max_steps: int, key: jax.random.KeyArray): \n",
    "  screen = env.render(mode='rgb_array')\n",
    "  im = Image.fromarray(screen)\n",
    "\n",
    "  images = [im]\n",
    "\n",
    "  state = jnp.array(env.reset())\n",
    "  for i in range(1, max_steps + 1):\n",
    "    key = jax.random.split(key, 2)[1]\n",
    "    action = model.act(state, key)\n",
    "    state, _, done, _ = env.step(action.item())\n",
    "    state = jnp.array(state)\n",
    "\n",
    "    # Render screen every 10 steps\n",
    "    if i % 10 == 0:\n",
    "      screen = env.render(mode='rgb_array')\n",
    "      images.append(Image.fromarray(screen))\n",
    "\n",
    "\n",
    "  return images\n",
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "# Save GIF image\n",
    "observation = env.reset()\n",
    "key = jax.random.PRNGKey(0)\n",
    "images = render_episode(env, eqx.tree_deserialise_leaves(\"checkpoints/cartpole/checkpoint_500.eqx\", ActorCritic(observation.shape[0], env.action_space.n, [64], [64], key=key)), 1000, key=key)\n",
    "image_file = 'cartpole-v0.gif'\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(\n",
    "    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00438e6e6465405d7e64b7e989cc9eee8ebcecea092b0d83b9c6ec6038b09b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
